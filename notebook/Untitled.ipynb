{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo52KjnEJbll",
        "colab_type": "text"
      },
      "source": [
        "# Font Finder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEBtoiM8JoRq",
        "colab_type": "code",
        "outputId": "f2f360a0-a799-4964-8b29-ea4c7283b257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH6EhyuFJbln",
        "colab_type": "text"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQqgSvfnJblp",
        "colab_type": "code",
        "outputId": "26fc011c-74da-4d04-f3ae-ab0d77e82083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        }
      },
      "source": [
        "!pip3 install torch torchvision torchsummary pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF8GMArDJbl0",
        "colab_type": "text"
      },
      "source": [
        "## H5PY Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcOUkXinJbl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "import h5py\n",
        "import torch\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filepath='datasets.hdf5', group='train'):\n",
        "        self.file = h5py.File(filepath, 'r')\n",
        "        self.class_num = self.file.attrs['class_num']\n",
        "        self.group = self.file[group]\n",
        "        self.length = len(self.group['data'])\n",
        "        self.current = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.group['data'][idx]\n",
        "        label = self.group['labels'][idx]\n",
        "        return (to_tensor(data), label.astype('i8'))\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.current < self.length:\n",
        "            item = self.__getitem__(self.current)\n",
        "            self.current += 1\n",
        "            return item\n",
        "        raise StopIteration\n",
        "\n",
        "    def close(self):\n",
        "        self.file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrRtUAxpJbl9",
        "colab_type": "text"
      },
      "source": [
        "## Class Names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy9kPc7YJbl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = [\n",
        "    'Ubuntu-Regular',\n",
        "    'PlayfairDisplay-Regular',\n",
        "    'PTAstraSans-Regular',\n",
        "    'PT Astra Serif_Regular',\n",
        "    'Akrobat-Regular',\n",
        "    'Golos Text_Regular',\n",
        "    'MontserratAlternates-Regular',\n",
        "    'Roboto-Regular',\n",
        "    'Gravity-Regular',\n",
        "    'Inter-Regular',\n",
        "    'SourceSansPro-Regular',\n",
        "    'EBGaramond-Regular',\n",
        "    'NotoSans-Regular',\n",
        "    'LiberationSerif-Regular',\n",
        "    'OpenSans-Regular',\n",
        "    'Merriweather-Regular',\n",
        "    'Arsenal-Regular',\n",
        "    'PlayfairDisplaySC-Regular',\n",
        "    'IBMPlexSerif-Regular',\n",
        "    'NotoSerif-Regular',\n",
        "    'PT Root UI_Regular',\n",
        "    'Lora-Regular',\n",
        "    'LiberationMono-Regular',\n",
        "    'Sansation_Regular',\n",
        "    'Montserrat-Regular',\n",
        "    'Alegreya-Regular',\n",
        "    'Spectral-Regular',\n",
        "    'IdealistSans-Regular',\n",
        "    'LiberationSans-Regular',\n",
        "    'Literata-Regular',\n",
        "    'PTSans-Regular',\n",
        "    'IBMPlexSans-Regular',\n",
        "    'FiraSans-Regular',\n",
        "    'UbuntuMono-Regular',\n",
        "    'Sreda-Regular',\n",
        "    'Oswald-Regular',\n",
        "    'Phenomena-Regular',\n",
        "    'Colus-Regular',\n",
        "    'BebasNeue-Regular',\n",
        "    'CormorantGaramond-Regular',\n",
        "    'NEXT ART_Regular',\n",
        "    'UbuntuCondensed-Regular'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvcv4dSsJbmD",
        "colab_type": "text"
      },
      "source": [
        "## Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfZGUU6zJbmF",
        "colab_type": "code",
        "outputId": "ef62a881-f3b4-4129-b888-32c6a136c70d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import random as rnd\n",
        "\n",
        "dataset = CustomDataset('/content/drive/My Drive/Colab Notebooks/datasets/dataset_254.hdf5')\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(25):\n",
        "    data, label = dataset[rnd.randint(0, len(dataset) - 1)]\n",
        "    image = to_pil_image(data)\n",
        "    label = class_names[label][:-len('-regular')]\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image, cmap=plt.cm.binary)\n",
        "    plt.xlabel(label)\n",
        "plt.show()\n",
        "dataset.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwh43rinJbmP",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9PzNgjjJbmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from pytorch_lightning import LightningModule\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes, expand_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        #self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1, bias=False)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.bn1 = nn.BatchNorm2d(squeeze_planes)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand_planes // 2, kernel_size=1, bias=False)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.bn2 = nn.BatchNorm2d(expand_planes // 2)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand_planes // 2, kernel_size=3, padding=1, bias=False)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "        self.bn3 = nn.BatchNorm2d(expand_planes // 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(self.squeeze_activation(self.squeeze(x)))\n",
        "        return torch.cat([\n",
        "            self.bn2(self.expand1x1_activation(self.expand1x1(x))),\n",
        "            self.bn3(self.expand3x3_activation(self.expand3x3(x)))\n",
        "        ], 1)\n",
        "\n",
        "\n",
        "class SqueezeNet(LightningModule):\n",
        "\n",
        "    def __init__(self, hparams):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        self.hparams = hparams\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, stride=2, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            Fire(64, 16, 128),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "            Fire(128, 32, 256),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "            Fire(256, 48, 384),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "            Fire(384, 64, 512),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "            Fire(512, 80, 640),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "            Fire(640, 96, 768),\n",
        "        )\n",
        "\n",
        "        # Final convolution is initialized differently from the rest\n",
        "        final_conv = nn.Conv2d(768, self.hparams.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return torch.flatten(x, 1)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self.forward(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        return { 'loss': loss }\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
        "        print(f'Train loss: {avg_loss}')\n",
        "        return { }\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self.forward(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        num_correct = pred.eq(target.view_as(pred)).sum()\n",
        "        return { 'val_loss': loss, 'num_correct': num_correct }\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "\n",
        "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        avg_accuracy = torch.stack([x['num_correct'] for x in outputs]).sum().float()\n",
        "        avg_accuracy /= (len(outputs) * self.hparams.batch_size)\n",
        "\n",
        "        print(f'Val loss: {avg_loss} acc: {avg_accuracy}')\n",
        "        \n",
        "        return {'val_loss': avg_loss, 'val_acc': avg_accuracy }\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adadelta(self.parameters(), lr=self.hparams.learning_rate)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, verbose=True)\n",
        "        return [ optimizer ], [ scheduler ]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZjRQ6cfJbmX",
        "colab_type": "text"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw2Csl6GJbmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "import argparse\n",
        "hparams = argparse.Namespace()\n",
        "hparams.num_classes = 42\n",
        "hparams.batch_size = 256\n",
        "hparams.learning_rate = 1 #1e-06\n",
        "\n",
        "model = SqueezeNet(hparams)\n",
        "#print(model)\n",
        "summary(model, (1, 127, 254), -1, 'cpu')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1          [-1, 64, 63, 126]             576\n              ReLU-2          [-1, 64, 63, 126]               0\n       BatchNorm2d-3          [-1, 64, 63, 126]             128\n            Conv2d-4          [-1, 16, 63, 126]           1,024\n              ReLU-5          [-1, 16, 63, 126]               0\n       BatchNorm2d-6          [-1, 16, 63, 126]              32\n            Conv2d-7          [-1, 64, 63, 126]           1,024\n              ReLU-8          [-1, 64, 63, 126]               0\n       BatchNorm2d-9          [-1, 64, 63, 126]             128\n           Conv2d-10          [-1, 64, 63, 126]           9,216\n             ReLU-11          [-1, 64, 63, 126]               0\n      BatchNorm2d-12          [-1, 64, 63, 126]             128\n             Fire-13         [-1, 128, 63, 126]               0\n        MaxPool2d-14          [-1, 128, 31, 63]               0\n           Conv2d-15           [-1, 32, 31, 63]           4,096\n             ReLU-16           [-1, 32, 31, 63]               0\n      BatchNorm2d-17           [-1, 32, 31, 63]              64\n           Conv2d-18          [-1, 128, 31, 63]           4,096\n             ReLU-19          [-1, 128, 31, 63]               0\n      BatchNorm2d-20          [-1, 128, 31, 63]             256\n           Conv2d-21          [-1, 128, 31, 63]          36,864\n             ReLU-22          [-1, 128, 31, 63]               0\n      BatchNorm2d-23          [-1, 128, 31, 63]             256\n             Fire-24          [-1, 256, 31, 63]               0\n        MaxPool2d-25          [-1, 256, 15, 31]               0\n           Conv2d-26           [-1, 48, 15, 31]          12,288\n             ReLU-27           [-1, 48, 15, 31]               0\n      BatchNorm2d-28           [-1, 48, 15, 31]              96\n           Conv2d-29          [-1, 192, 15, 31]           9,216\n             ReLU-30          [-1, 192, 15, 31]               0\n      BatchNorm2d-31          [-1, 192, 15, 31]             384\n           Conv2d-32          [-1, 192, 15, 31]          82,944\n             ReLU-33          [-1, 192, 15, 31]               0\n      BatchNorm2d-34          [-1, 192, 15, 31]             384\n             Fire-35          [-1, 384, 15, 31]               0\n        MaxPool2d-36           [-1, 384, 7, 15]               0\n           Conv2d-37            [-1, 64, 7, 15]          24,576\n             ReLU-38            [-1, 64, 7, 15]               0\n      BatchNorm2d-39            [-1, 64, 7, 15]             128\n           Conv2d-40           [-1, 256, 7, 15]          16,384\n             ReLU-41           [-1, 256, 7, 15]               0\n      BatchNorm2d-42           [-1, 256, 7, 15]             512\n           Conv2d-43           [-1, 256, 7, 15]         147,456\n             ReLU-44           [-1, 256, 7, 15]               0\n      BatchNorm2d-45           [-1, 256, 7, 15]             512\n             Fire-46           [-1, 512, 7, 15]               0\n        MaxPool2d-47            [-1, 512, 3, 7]               0\n           Conv2d-48             [-1, 80, 3, 7]          40,960\n             ReLU-49             [-1, 80, 3, 7]               0\n      BatchNorm2d-50             [-1, 80, 3, 7]             160\n           Conv2d-51            [-1, 320, 3, 7]          25,600\n             ReLU-52            [-1, 320, 3, 7]               0\n      BatchNorm2d-53            [-1, 320, 3, 7]             640\n           Conv2d-54            [-1, 320, 3, 7]         230,400\n             ReLU-55            [-1, 320, 3, 7]               0\n      BatchNorm2d-56            [-1, 320, 3, 7]             640\n             Fire-57            [-1, 640, 3, 7]               0\n        MaxPool2d-58            [-1, 640, 1, 3]               0\n           Conv2d-59             [-1, 96, 1, 3]          61,440\n             ReLU-60             [-1, 96, 1, 3]               0\n      BatchNorm2d-61             [-1, 96, 1, 3]             192\n           Conv2d-62            [-1, 384, 1, 3]          36,864\n             ReLU-63            [-1, 384, 1, 3]               0\n      BatchNorm2d-64            [-1, 384, 1, 3]             768\n           Conv2d-65            [-1, 384, 1, 3]         331,776\n             ReLU-66            [-1, 384, 1, 3]               0\n      BatchNorm2d-67            [-1, 384, 1, 3]             768\n             Fire-68            [-1, 768, 1, 3]               0\n          Dropout-69            [-1, 768, 1, 3]               0\n           Conv2d-70             [-1, 42, 1, 3]          32,298\n             ReLU-71             [-1, 42, 1, 3]               0\nAdaptiveAvgPool2d-72             [-1, 42, 1, 1]               0\n================================================================\nTotal params: 1,115,274\nTrainable params: 1,115,274\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.12\nForward/backward pass size (MB): 73.75\nParams size (MB): 4.25\nEstimated Total Size (MB): 78.13\n----------------------------------------------------------------\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUeI3P7yJbmd",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Y-wzWQLl84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p saves/main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgf4u_j1Jbmd",
        "colab_type": "code",
        "outputId": "dee34710-0b17-44c0-f539-8d1b824c1a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cc380f9e77504a3c8f51943900e08d6a",
            "e29504fb8a954e6989c3c81b90d4bb53",
            "b5a4e04797d1496d976f73a3a0a21e18",
            "bbffc611391c4d2790a17fb3aa57ad34",
            "41298ad2bc2a4433976bebef58943174",
            "c449d7b343524e2686a1347fb56d89d8",
            "87731a085ce1458a968166b08554a345",
            "a6600cc121c6464ab47f3307374320bf",
            "15dae712e87e4ef7a2fe35fa2e159587",
            "584cdd8a44a940ef98255d63be040d26",
            "aa8fbd42d309408e9c379f429931a77e",
            "22c3619c38f3494b8a2065438a1ef793",
            "c7afc8e8553e45ab978d1100aa53e47d"
          ]
        }
      },
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    'saves/main',\n",
        "    monitor='val_acc',\n",
        "    save_top_k=10\n",
        ")\n",
        "\n",
        "kwargs = {'num_workers': 6, 'pin_memory': True}\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    CustomDataset('/content/drive/My Drive/Colab Notebooks/datasets/dataset_254.hdf5'),\n",
        "    batch_size=hparams.batch_size, shuffle=True, #**kwargs\n",
        ")\n",
        "val_loader   = DataLoader(\n",
        "    CustomDataset('/content/drive/My Drive/Colab Notebooks/datasets/dataset_381.hdf5'),\n",
        "    batch_size=hparams.batch_size, shuffle=False, #**kwargs\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    gpus=1,\n",
        "    max_epochs=35,\n",
        "    val_percent_check = 0.1,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    auto_lr_find=True,\n",
        "    #resume_from_checkpoint='saves/main/epoch=5.ckpt'\n",
        ")\n",
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTL62UoPSXd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    },
    "colab": {
      "name": "Copy of Untitled.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc380f9e77504a3c8f51943900e08d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2906642a3b994262af9042b95fcadb42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee3f1d2fe16f41afa0d1ec0eb8161ab7",
              "IPY_MODEL_1b3b8b23651a4fdd8a30ed137106b9c4"
            ]
          }
        },
        "e29504fb8a954e6989c3c81b90d4bb53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ade98840cb8e4e0ba4c1a236286d0976",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aed1a29752874dfbb59f110c9667294b",
              "IPY_MODEL_070e7168ebc042b7863e5312bca6832d"
            ]
          }
        },
        "b5a4e04797d1496d976f73a3a0a21e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b16f7eb08c204a918639f1b94f2f5ae7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88fc4596ad774bf9bde19f0b5fd5f855",
              "IPY_MODEL_8341103ca4b947d89cbb2dcadc855f5c"
            ]
          }
        },
        "bbffc611391c4d2790a17fb3aa57ad34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_153d57b22e6c4a55985d4f283ce96398",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a001aa20a8ea4c48b6d0898ed3c6ac7d",
              "IPY_MODEL_3ba6deeea3b44826842354f0c0b64d46"
            ]
          }
        },
        "41298ad2bc2a4433976bebef58943174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_04c5e3592ba5486a9e01e0454f30053e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e6358157ba54f7d87f23c80debceb4a",
              "IPY_MODEL_06a76cecf2464d819a9855c6fed14378"
            ]
          }
        },
        "c449d7b343524e2686a1347fb56d89d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_54f3c3a8c9bc4486926fa13ee4c57c33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75f0fc253466423484a5b3c50a9a4a6c",
              "IPY_MODEL_338c5f82ca6147ba9583bedededef63c"
            ]
          }
        },
        "87731a085ce1458a968166b08554a345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6b0f53fed4a44806b1af1a05da831ccb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_930e5b49619443b8b0b02bf2ec6442da",
              "IPY_MODEL_19e8750faa1643f8a1b6b81c7d42b1f6"
            ]
          }
        },
        "a6600cc121c6464ab47f3307374320bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6739ae0ca3534acebd6d53c46c32dc83",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73a7d26c48134396a8afb90cb739d965",
              "IPY_MODEL_8a8229804edd42edb53f58e563b694ad"
            ]
          }
        },
        "15dae712e87e4ef7a2fe35fa2e159587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f4c129aebb84ea79f8c1907b3021cf8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca315b6800a546198750b3a180e3b1e3",
              "IPY_MODEL_7f137caa809f44f4bd12cc629fadcaca"
            ]
          }
        },
        "584cdd8a44a940ef98255d63be040d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1499218c99a6471f8547f5dc61ee452c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7eb8c02399d24a76859fdbfd72b72f35",
              "IPY_MODEL_65e5d27961ab4200ba7048d8f43a3d78"
            ]
          }
        },
        "aa8fbd42d309408e9c379f429931a77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a6ee8bb766ea4b47af92aab089e7cf35",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_900deef51b764b88bb37ea07c5bab760",
              "IPY_MODEL_5b7077da05e9414d92c411eeb7fbe3b2"
            ]
          }
        },
        "22c3619c38f3494b8a2065438a1ef793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2d17acb920f40ba8e9c15faa432d8cf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07c2e7fe343c4980b84dcca78ebed74e",
              "IPY_MODEL_ba9a5c2defe648d48dcfa3fd5cd2a86a"
            ]
          }
        },
        "c7afc8e8553e45ab978d1100aa53e47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_232574e4a63d429598683f4d8247c7d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee1ab3b63fa744ee9ca5890507c5d09a",
              "IPY_MODEL_1680cf51e2e849748846bc64e7d5068a"
            ]
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}